{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":["'''\n","IMPORTANT INSTRUCTIONS!!!\n","\n","1. Before Proceeding, add dataset : www.kaggle.com/srikaranand/road-segmentation-dataset\n","   (click 'Add Data' button and then 'click search from URL')\n","\n","2. To run the program,  run cells #11 , #12 and #13  (Cell numbers at top of each cell)\n","\n","'''\n","\n","\n","\n","#1\n","%matplotlib inline\n","import itertools\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import keras\n","from keras import losses\n","from keras.datasets import mnist\n","from keras.models import Sequential, model_from_json\n","\n","from keras.layers import Dense, Dropout, Flatten, Reshape, Conv2D, MaxPooling2D, LeakyReLU\n","from keras import backend as K\n","from keras.optimizers import Adam\n","\n","#from keras.utils.training_utils import multi_gpu_model\n","\n","#from helpers import *"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":"Using TensorFlow backend.\n"}]},{"metadata":{"trusted":false},"cell_type":"code","source":["#2\n","print(keras.__version__)\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":["#3\n","imgs, gt_imgs = training_dataset(limit=100)\n","print('Image size =', imgs[0].shape)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":["#4\n","patch_size = 16 # each patch is 16*16 pixels"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":["#5\n","train_data = [\n","    (patch, gt_patch)\n","    for i in range(len(imgs))\n","    for patch, gt_patch initertools.islice(gen_random_patches(reflect_border(imgs[i], patch_size, 2),\n","                                                              reflect_border(gt_imgs[i], patch_size, 2), i), 25*25*8)]\n","\n","\n","X = np.asarray([img for img, _ in train_data])\n","y = np.asarray([value_to_class(gt_patch) for _, gt_patch in train_data]).reshape((-1, 1))\n","\n","print(X.shape)\n","print(y.shape)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":["#6\n","# Model parameters\n","\n","batch_size = 64 * 8\n","num_filters_1 = 16\n","num_filters_2 = 32\n","num_filters_3 = 64\n","num_filters_4 = 128\n","\n","epochs = 50"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":["#7\n","def build_model(gpus=0):\n","    model = Sequential()\n","    model.add(Conv2D(num_filters_1, kernel_size=(4, 4), input_shape=(80, 80, 3)))\n","    model.add(LeakyReLU(alpha=0.1))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(num_filters_2, kernel_size=(4,4)))\n","    model.add(LeakyReLU(alpha=0.1))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(num_filters_3, kernel_size=(4,4)))\n","    model.add(LeakyReLU(alpha=0.1))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(num_filters_4, kernel_size=(4,4)))\n","    model.add(LeakyReLU(alpha=0.1))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    simple_model = model\n","    if gpus > 1:\n","        model = multi_gpu_model(simple_model, gpus=gpus)\n","\n","    model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(lr=1e-3),\n","              metrics=['accuracy'])\n","    \n","    return (model, simple_model)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":["#8\n","model, simple_model = build_model(0)\n","model.summary()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":["#9\n","model.fit(X, y,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          shuffle=True)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":["#10\n","# save the model and the weights to files\n","model_json = simple_model.to_json()\n","with open('savedModels/model_18', 'w') as f:\n","    f.write(model_json)\n","\n","simple_model.save_weights('savedModels/weights_18')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["#11\n","#helpers.py\n","!pip install imutils\n","import os,sys\n","import re\n","import cv2\n","#import imutils\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import numpy as np\n","import random\n","\n","patch_size = 16\n","\n","\n","\n","def load_image(infilename):\n","    data = mpimg.imread(infilename)\n","    return data\n","\n","\n","def img_float_to_uint8(img):\n","    rimg = img - np.min(img)\n","    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n","    return rimg\n","\n","def concatenate_images(img, gt_img):\n","    nChannels = len(gt_img.shape)\n","    w = gt_img.shape[0]\n","    h = gt_img.shape[1]\n","    if nChannels == 3:\n","        cimg = np.concatenate((img, gt_img), axis=1)\n","    else:\n","        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n","        gt_img8 = img_float_to_uint8(gt_img)          \n","        gt_img_3c[:,:,0] = gt_img8\n","        gt_img_3c[:,:,1] = gt_img8\n","        gt_img_3c[:,:,2] = gt_img8\n","        img8 = img_float_to_uint8(img)\n","        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n","    return cimg\n","\n","\n","def img_crop(im, w, h):\n","    list_patches = []\n","    imgwidth = im.shape[0]\n","    imgheight = im.shape[1]\n","    is_2d = len(im.shape) < 3\n","    for i in range(0,imgheight,h):\n","        for j in range(0,imgwidth,w):\n","            if is_2d:\n","                im_patch = im[i:i+w, j:j+h]\n","            else:\n","                im_patch = im[i:i+w, j:j+h, :]\n","            list_patches.append(im_patch)\n","    return list_patches\n","\n","\n","def reflect_border(im, patch_size, count):\n","    bordersize = patch_size*count\n","    border = cv2.copyMakeBorder(im,\n","                              top=bordersize,\n","                              bottom=bordersize, \n","                              left=bordersize,\n","                              right=bordersize,\n","                              borderType=cv2.BORDER_REFLECT)\n","    return border\n","\n","def rotate_image(img, rot_degrees=[0, 90, 180, 270]):\n","    return [\n","        imutils.rotate_bound(img, rot)\n","        for rot in rot_degrees\n","    ]\n","\n","\n","def flip_image(img):\n","    return cv2.flip(img, 1)\n","\n","\n","def image_trans(img):\n","    return [\n","        t_img\n","        for rot_img in rotate_image(img)\n","        for t_img in [rot_img, flip_image(rot_img)]\n","    ]\n","\n","\n","def training_dataset(limit=100, root_dir='input/road-segmentation-dataset/data/training/'):\n","    image_dir = root_dir + \"images/\"\n","    files = os.listdir(image_dir)\n","    n = min(limit, len(files))\n","    print('Loading', n, 'training images')\n","    imgs = [load_image(image_dir + files[i]) for i in range(n)]\n","    gt_dir = root_dir + \"groundtruth/\"\n","    print('Loading', n, 'groundtruth images')\n","    gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n","    return (imgs, gt_imgs)\n","\n","def label_to_img(imgwidth, imgheight, w, h, labels):\n","    im = np.zeros([imgwidth, imgheight])\n","    idx = 0\n","    for i in range(0,imgheight,h):\n","        for j in range(0,imgwidth,w):\n","            im[i:i+w, j:j+h] = labels[idx]\n","            idx = idx + 1\n","    return im\n","\n","def make_img_overlay(img, predicted_img):\n","    w = img.shape[0]\n","    h = img.shape[1]\n","    color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n","    color_mask[:,:,0] = predicted_img*255\n","\n","    img8 = img_float_to_uint8(img)\n","    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n","    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n","    new_img = Image.blend(background, overlay, 0.2)\n","    return new_img\n","\n","def print_prediction(img, gt_img, model):\n","    img_patches = [\n","        img_patch\n","        for img_patch in image_to_patches(reflect_border(img, patch_size, 2), get_image_crop)\n","    ]\n","\n","    gt_labeled_patches = [\n","        value_to_class(gt_patch)\n","        for gt_patch in image_to_patches(reflect_border(gt_img, patch_size, 2), get_groundtruth_crop)\n","    ]\n","\n","    predicted_patches = model.predict(np.asarray(img_patches))\n","    \n","    w = img.shape[0]\n","    h = img.shape[1]\n","    predicted_im = label_to_img(w, h, patch_size, patch_size, predicted_patches)\n","    \n","    \n","    print(\"Ground truth\")\n","    cimg = concatenate_images(img, gt_img)\n","    fig1 = plt.figure(figsize=(10, 10))\n","    plt.imshow(cimg, cmap='Greys_r')\n","    plt.show()\n","    \n","    print(\"Ground truth patches\")\n","    gt_im_patches = label_to_img(w, h, patch_size, patch_size, gt_labeled_patches)\n","\n","    cimg = concatenate_images(img, gt_im_patches)\n","    fig1 = plt.figure(figsize=(10, 10)) \n","    plt.imshow(cimg, cmap='Greys_r')\n","    plt.show()\n","    \n","    print(\"Predicted patches\")\n","\n","    cimg = concatenate_images(img, predicted_im)\n","    fig1 = plt.figure(figsize=(10, 10))  \n","    plt.imshow(cimg, cmap='Greys_r')\n","    plt.show()\n","    \n","    print(\"Prediction overlay\")\n","\n","    new_img = make_img_overlay(img, predicted_im)\n","\n","    plt.imshow(new_img)\n","\n","def image_to_patches(img, func):\n","    p = img.shape\n","    assert p[0] == p[1]\n","    n = p[0]\n","    patches = [\n","        func(img, i, j)\n","        for i in range(2*patch_size, n - 3*patch_size+1, patch_size)\n","        for j in range(2*patch_size, n - 3*patch_size+1, patch_size)\n","    ]\n","    return patches\n","\n","def get_image_crop(img, i, j):\n","    return img[i-2*patch_size:i+3*patch_size, j-2*patch_size:j+3*patch_size, :]\n","\n","def get_groundtruth_crop(gt_img, i, j):\n","    return gt_img[i:i+patch_size, j:j+patch_size]\n","\n","def value_to_class(v, foreground_threshold = 0.25):\n","    df = np.mean(v)\n","    return (df > foreground_threshold) * 1\n","\n","\n","def gen_random_patches(img, gt, seed=42):\n","    random.seed(seed)\n","    n = img.shape[0]\n","    \n","    angle = random.choice([0, 90, 180, 270])\n","    \n","    rot_img = rotate_image(img, [angle])[0]\n","    rot_gt = rotate_image(gt, [angle])[0]\n","    \n","    if random.randrange(2) == 1:\n","        rot_img = flip_image(rot_img)\n","        rot_gt = flip_image(rot_gt)\n","                           \n","    while True:\n","        x = random.randrange(n - 80)\n","        y = random.randrange(n - 80)\n","        yield (\n","            rot_img[x:x+80,y:y+80,:],\n","            rot_gt[x+2*patch_size:x+3*patch_size,\n","                   y+2*patch_size:y+3*patch_size]\n","        )\n","\n","def label_to_img(imgwidth, imgheight, w, h, labels):\n","    im = np.zeros([imgwidth, imgheight])\n","    idx = 0\n","    for i in range(0,imgheight,h):\n","        for j in range(0,imgwidth,w):\n","            im[i:i+w, j:j+h] = labels[idx]\n","            idx = idx + 1\n","    return im\n","            \n","            \n","def img_to_submission_strings(labels, img_number, w, h, patch_size):\n","    \"\"\"outputs the strings that should go into the submission file for a given image\"\"\"\n","    label_img = labels.reshape(w//patch_size,h//patch_size)\n","    for j in range(0, w, patch_size):\n","        for i in range(0, h, patch_size):\n","            label = label_img[i//patch_size][j//patch_size]\n","            if label >= 0.5:\n","                sub_lab = 1\n","            else:\n","                sub_lab = 0\n","                \n","            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, sub_lab))\n","\n","            \n","def image_to_inputs(img, patch_size):\n","    rows, cols, _ = img.shape\n","    \n","    patches = [\n","        \n","            img[i-2*patch_size:i+3*patch_size, j-2*patch_size:j+3*patch_size, :]\n","        \n","        for i in range(2*patch_size, rows - 3*patch_size+1, patch_size)\n","        for j in range(2*patch_size, cols - 3*patch_size+1, patch_size)\n","    ]\n","\n","    return patches\n","\n","\n","def disp_img_pred(img, pred, patch_size):\n","    w = img.shape[0]\n","    h = img.shape[1]\n","    predicted_im = label_to_img(w, h, patch_size, patch_size, pred)\n","    new_img = make_img_overlay(img, predicted_im)\n","    fig1 = plt.figure(figsize=(10,10))\n","    plt.imshow(new_img)\n","    plt.show()\n","\n","\n","def make_img_overlay(img, predicted_img):\n","    w = img.shape[0]\n","    h = img.shape[1]\n","    color_mask = np.zeros((w, h, 3), dtype=np.uint8)\n","    color_mask[:,:,0] = predicted_img*255\n","    img8 = img_float_to_uint8(img)\n","    background = Image.fromarray(img8, 'RGB').convert(\"RGBA\")\n","    overlay = Image.fromarray(color_mask, 'RGB').convert(\"RGBA\")\n","    new_img = Image.blend(background, overlay, 0.2)\n","    return new_img\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: imutils in c:\\users\\srika\\appdata\\roaming\\python\\python36\\site-packages (0.5.3)\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["#12\n","#run.py\n","\n","import itertools\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras\n","\n","from keras import losses\n","from keras.datasets import mnist\n","from keras.models import Sequential, model_from_json\n","\n","from keras.layers import Dense, Dropout, Flatten, Reshape, Conv2D, MaxPooling2D, LeakyReLU\n","from keras import backend as K\n","from keras.optimizers import Adam\n","\n","import imutils\n","\n","\n","#from helpers import *\n","\n","patch_size = 16 #size of each batch of pixels\n","\n","\n","imgs, gt_imgs = training_dataset(limit=10)\n","\n","train_data = [\n","    (patch, gt_patch)\n","    for i in range(len(imgs))\n","    for patch, gt_patch in itertools.islice(gen_random_patches(reflect_border(imgs[i], patch_size, 2),\n","                                                              reflect_border(gt_imgs[i], patch_size, 2), i), 25*25*8)]\n","\n","\n","X = np.asarray([img for img, _ in train_data])\n","y = np.asarray([value_to_class(gt_patch) for _, gt_patch in train_data]).reshape((-1, 1))\n","\n","\n","batch_size = 64\n","num_filters_1 = 16\n","num_filters_2 = 32\n","num_filters_3 = 64\n","num_filters_4 = 128\n","\n","epochs = 50\n","\n","def build_model(gpus=0):\n","    model = Sequential()\n","    model.add(Conv2D(num_filters_1, kernel_size=(4, 4), input_shape=(80, 80, 3)))\n","    model.add(LeakyReLU(alpha=0.1))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(num_filters_2, kernel_size=(4,4)))\n","    model.add(LeakyReLU(alpha=0.1))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(num_filters_3, kernel_size=(4,4)))\n","    model.add(LeakyReLU(alpha=0.1))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(num_filters_4, kernel_size=(4,4)))\n","    model.add(LeakyReLU(alpha=0.1))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    simple_model = model\n","    if gpus > 1:\n","        model = multi_gpu_model(simple_model, gpus=gpus)\n","\n","    model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(lr=1e-3),\n","              metrics=['accuracy'])\n","    \n","    return (model, simple_model)\n","\n","model, simple_model = build_model(0)\n","model.summary()\n","\n","\n","\n","#model.fit(X, y,batch_size=batch_size, epochs=epochs,verbose=1, shuffle=True)\n","\n","\n","#model_json = simple_model.to_json()\n","#with open('model_18', 'w') as f:\n","#    f.write(model_json)\n","\n","#simple_model.save_weights('weights_18')\n","\n","\n","fm = open('input/road-segmentation-dataset/model_18') #pre-trained weights\n","model = model_from_json(fm.read())\n","fm.close()\n","\n","model.load_weights('input/road-segmentation-dataset/weights_18', by_name=False)\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(lr=1e-3),#'rmsprop',\n","              metrics=['accuracy'])\n","\n","\n","foreground_threshold = 0.5 \n","patch_size = 16\n","\n","def pred_print(img, img_patches):\n","    print('Prediction started...')\n","    pred = [\n","        np.round((np.median(model.predict(np.asarray(image_trans(patch))))))\n","        for patch in img_patches\n","    ]\n","    pred = np.asarray(pred)\n","    print('Prediction done...')\n","    #disp_img_pred(img, pred, patch_size)\n","    return pred\n","\n","\n","def submission_with_model(model, submissionfilename):\n","\n","    root_dir = \"input/road-segmentation-dataset/data/test_set_images/\"\n","\n","    \n","    image_dir = [root_dir + \"test_{}/\".format(i) for i in range(1, 51)]\n","    filenames = [fn for imdir in image_dir for fn in os.listdir(imdir)]\n","    images = [load_image(image_dir[i-1] + filenames[i-1]) for i in range(1, 51)]\n","\n","    \n","    im_borders = [reflect_border(im, patch_size, 2) for im in images]\n","    \n","    \n","    imgs_patched = [image_to_inputs(im, patch_size) for im in im_borders]\n","    \n","    \n","    n_images = 1   #number of test images to predict\n","\n","\n","    predictions = []\n","    for i in range(1,n_images+1):\n","        predictions.append(pred_print(images[i-1], np.asarray(imgs_patched[i-1])))\n","    \n","    with open(submissionfilename, 'w') as f:\n","        for nr in range(1, n_images+1):\n","            f.writelines(\n","                '{}\\n'.format(s)\n","                for s in img_to_submission_strings(predictions[nr-1],\n","                                                   nr,\n","                                                   images[nr-1].shape[1],\n","                                                   images[nr-1].shape[0],\n","                                                   patch_size))\n","\n","submission_with_model(model, 'output.csv')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":"Using TensorFlow backend.\nLoading 10 training images\nLoading 10 groundtruth images\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 77, 77, 16)        784       \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 77, 77, 16)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 38, 38, 16)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 38, 38, 16)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 35, 35, 32)        8224      \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 35, 35, 32)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 17, 17, 32)        0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 17, 17, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 14, 14, 64)        32832     \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 7, 7, 64)          0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 4, 4, 128)         131200    \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 2, 2, 128)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 173,553\nTrainable params: 173,553\nNon-trainable params: 0\n_________________________________________________________________\nPrediction started...\nPrediction done...\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["#13\n","#csv2img.py\n","\n","# This program converts the csv output to images\n","\n","import csv\n","from PIL import Image\n","\n","\n","n_images = 1\n","\n","images=[]\n","for _ in range(n_images):\n","  img = Image.new('RGB',[593,593])\n","  images.append(img)\n","  #print(img1.mode)\n","\n","with open('output.csv') as csvfile:\n","    readCSV = csv.reader(csvfile, delimiter=',')\n","    for row in readCSV:\n","        records = row[0].split('_')\n","        value = int(row[1])*255\n","        i = int(records[0])-1\n","        x = int(records[1])\n","        y = int(records[2])\n","        img = images[i].load()\n","        img[x,y] = (value, value,value)\n","\n","img_num=0\n","for img1 in images:\n","  output = img1\n","  output_ = output.load()\n","  for i in range(img1.size[0]):\n","    for j in range(img1.size[1]):\n","      x = (i//16) * 16\n","      y = (j//16) * 16\n","      output_[i,j] = img[x,y]\n","  img_num=img_num+1\n","  output.save('output/mask_'+str(img_num)+'.png')\n","print('Images saved in output directory')"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"Images saved in output directory\n"}]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["#14\n","#masking\n","from PIL import Image\n","\n","color = (0,0,0)\n","\n","def mask(pic,mask,outpic):\n","    img = Image.open(pic)\n","    mask = Image.open(mask)\n","    img = img.resize(mask.size)\n","    img_pix = img.load()\n","    mask_pix = mask.load()\n","    for i in range(img.size[0]):\n","        for j in range(img.size[1]):\n","            if sum(mask_pix[i,j])/3 > 127:\n","                img_pix[i,j] = color\n","    img.save(outpic)\n","\n","mask('input/road-segmentation-dataset/data/test_set_images/test_1/test_1.png','output/mask_1.png','output/final_output_1.png')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5-final"}},"nbformat":4,"nbformat_minor":4}